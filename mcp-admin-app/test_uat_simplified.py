#!/usr/bin/env python3
"""
Simplified User Acceptance Testing (UAT) for MCP Admin Application

This UAT focuses on testing the core user workflows that are currently implemented.
Task 20.2: Perform user acceptance testing and optimization
"""

import os
import sys
import tempfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path

# Add the parent directory to the path to import modules
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Core imports
from core.config import ConfigurationManager
from data.database import DatabaseManager

# Service imports
from services.server_manager import ServerManager
from services.tool_manager import AdvancedToolManager
from services.tool_discovery import ToolDiscoveryEngine
from services.tool_execution import ToolExecutionEngine
from services.security_service import SecurityService
from services.audit_service import AuditService

# Model imports
from models.base import ServerStatus, RiskLevel


class SimplifiedUAT:
    """Simplified User Acceptance Testing focusing on core workflows"""
    
    def __init__(self):
        """Initialize UAT environment"""
        self.test_dir = tempfile.mkdtemp(prefix="mcp_admin_uat_simple_")
        self.config_manager = None
        self.db_manager = None
        self.services = {}
        self.test_results = {}
        
    def setup_uat_environment(self):
        """Set up UAT environment"""
        print("Setting up Simplified UAT environment...")
        
        try:
            # Initialize configuration
            self.config_manager = ConfigurationManager()
            self.config_manager.initialize()
            
            # Initialize database
            test_db_path = Path(self.test_dir) / "uat_simple.db"
            self.db_manager = DatabaseManager(test_db_path)
            self.db_manager.initialize()
            
            # Initialize services
            self.services = {
                'server_manager': ServerManager(self.config_manager, self.db_manager),
                'tool_manager': AdvancedToolManager(self.db_manager),
                'tool_discovery': ToolDiscoveryEngine(),
                'tool_execution': ToolExecutionEngine(self.db_manager),
                'security_service': SecurityService(self.db_manager),
                'audit_service': AuditService(self.db_manager)
            }
            
            print("‚úì Simplified UAT environment setup complete")
            return True
            
        except Exception as e:
            print(f"‚úó UAT environment setup failed: {e}")
            return False
    
    def test_scenario_1_basic_server_operations(self):
        """Test basic server management operations"""
        print("\nüß™ UAT Scenario 1: Basic Server Operations")
        
        try:
            server_manager = self.services['server_manager']
            
            print("   üìã Testing basic server operations...")
            
            # Step 1: Check initial server list
            initial_servers = server_manager.get_servers()
            initial_count = len(initial_servers)
            print(f"   ‚úì Step 1: Found {initial_count} initial servers")
            
            # Step 2: Add a new server
            server_config = {
                "name": "UAT Test Server",
                "command": "python",
                "args": ["-m", "test_server"],
                "description": "Server created during UAT"
            }
            
            server_id = server_manager.add_server(server_config)
            print("   ‚úì Step 2: Successfully added new server")
            
            # Step 3: Verify server was added
            updated_servers = server_manager.get_servers()
            assert len(updated_servers) == initial_count + 1, "Server count should increase"
            print("   ‚úì Step 3: Server count increased correctly")
            
            # Step 4: Retrieve server details
            server = server_manager.get_server(server_id)
            assert server is not None, "Should retrieve server"
            assert server.name == "UAT Test Server", "Server name should match"
            print("   ‚úì Step 4: Server details retrieved correctly")
            
            self.test_results['server_operations'] = True
            print("   ‚úÖ Basic Server Operations: PASSED")
            
        except Exception as e:
            self.test_results['server_operations'] = False
            print(f"   ‚ùå Basic Server Operations: FAILED - {e}")
    
    def test_scenario_2_tool_discovery_workflow(self):
        """Test tool discovery workflow"""
        print("\nüß™ UAT Scenario 2: Tool Discovery Workflow")
        
        try:
            tool_discovery = self.services['tool_discovery']
            tool_manager = self.services['tool_manager']
            
            print("   üìã Testing tool discovery workflow...")
            
            # Step 1: Check initial tool count
            initial_tools = tool_manager.get_all_tools()
            initial_count = len(initial_tools)
            print(f"   ‚úì Step 1: Found {initial_count} initial tools")
            
            # Step 2: Discover tools from a server
            discovered_tools = tool_discovery.scan_server_tools("uat-test-server")
            assert len(discovered_tools) > 0, "Should discover some tools"
            print(f"   ‚úì Step 2: Discovered {len(discovered_tools)} tools")
            
            # Step 3: Register discovered tools
            for discovered in discovered_tools:
                tool_manager.register_tool(discovered)
            print("   ‚úì Step 3: Registered discovered tools")
            
            # Step 4: Verify tools were registered
            updated_tools = tool_manager.get_all_tools()
            assert len(updated_tools) > initial_count, "Tool count should increase"
            print(f"   ‚úì Step 4: Tool count increased to {len(updated_tools)}")
            
            # Step 5: Search for tools
            search_results = tool_manager.search_tools("file")
            print(f"   ‚úì Step 5: Search found {len(search_results)} file-related tools")
            
            self.test_results['tool_discovery'] = True
            print("   ‚úÖ Tool Discovery Workflow: PASSED")
            
        except Exception as e:
            self.test_results['tool_discovery'] = False
            print(f"   ‚ùå Tool Discovery Workflow: FAILED - {e}")
    
    def test_scenario_3_tool_execution_basics(self):
        """Test basic tool execution"""
        print("\nüß™ UAT Scenario 3: Basic Tool Execution")
        
        try:
            tool_manager = self.services['tool_manager']
            tool_execution = self.services['tool_execution']
            
            print("   üìã Testing basic tool execution...")
            
            # Step 1: Get available tools
            tools = tool_manager.get_all_tools()
            assert len(tools) > 0, "Should have tools available"
            test_tool = tools[0]  # Use first available tool
            print(f"   ‚úì Step 1: Selected tool '{test_tool.name}' for testing")
            
            # Step 2: Test parameter validation
            test_params = {"input": "test data"}
            validation_result = tool_execution.validate_parameters(test_tool, test_params)
            print(f"   ‚úì Step 2: Parameter validation result: {validation_result[0]}")
            
            # Step 3: Execute tool (if validation passes)
            if validation_result[0]:
                from services.tool_execution import ExecutionRequest
                request = ExecutionRequest(
                    tool_id=test_tool.id,
                    user_id="uat_user",
                    parameters=test_params
                )
                
                execution_result = tool_execution.execute_tool(request, test_tool)
                assert execution_result is not None, "Should get execution result"
                print("   ‚úì Step 3: Tool execution completed")
            else:
                print("   ‚ö†Ô∏è  Step 3: Skipped execution due to validation failure")
            
            # Step 4: Check execution history
            history = tool_execution.get_execution_history()
            print(f"   ‚úì Step 4: Found {len(history)} execution records")
            
            self.test_results['tool_execution'] = True
            print("   ‚úÖ Basic Tool Execution: PASSED")
            
        except Exception as e:
            self.test_results['tool_execution'] = False
            print(f"   ‚ùå Basic Tool Execution: FAILED - {e}")
    
    def test_scenario_4_security_audit_logging(self):
        """Test security and audit logging"""
        print("\nüß™ UAT Scenario 4: Security and Audit Logging")
        
        try:
            security_service = self.services['security_service']
            audit_service = self.services['audit_service']
            
            print("   üìã Testing security and audit logging...")
            
            # Step 1: Log a security event
            from models.security import SecurityEvent
            from models.base import SecurityEventType
            security_event = SecurityEvent(
                event_type=SecurityEventType.TOOL_EXECUTION,
                user="uat_user",
                resource="test_tool",
                details={"test": "uat", "description": "UAT security event test"},
                risk_level=RiskLevel.LOW,
                timestamp=datetime.now()
            )
            
            security_service.log_security_event(security_event)
            print("   ‚úì Step 1: Security event logged")
            
            # Step 2: Retrieve security events
            recent_events = security_service.get_security_events(limit=10)
            assert len(recent_events) > 0, "Should find security events"
            print(f"   ‚úì Step 2: Found {len(recent_events)} security events")
            
            # Step 3: Log an audit action
            audit_service.log_action(
                user_id="uat_user",
                action="uat_test",
                resource_type="test",
                resource_id="uat-test-1",
                details={"test_type": "user_acceptance"}
            )
            print("   ‚úì Step 3: Audit action logged")
            
            # Step 4: Retrieve audit events
            recent_audit = audit_service.get_audit_events(limit=10)
            assert len(recent_audit) > 0, "Should find audit events"
            print(f"   ‚úì Step 4: Found {len(recent_audit)} audit events")
            
            self.test_results['security_audit'] = True
            print("   ‚úÖ Security and Audit Logging: PASSED")
            
        except Exception as e:
            self.test_results['security_audit'] = False
            print(f"   ‚ùå Security and Audit Logging: FAILED - {e}")
    
    def test_scenario_5_tool_management_operations(self):
        """Test tool management operations"""
        print("\nüß™ UAT Scenario 5: Tool Management Operations")
        
        try:
            tool_manager = self.services['tool_manager']
            
            print("   üìã Testing tool management operations...")
            
            # Step 1: Get tool statistics
            stats = tool_manager.get_tool_statistics()
            assert stats['total_tools'] >= 0, "Should get tool statistics"
            print(f"   ‚úì Step 1: Tool statistics - {stats['total_tools']} total tools")
            
            # Step 2: Create a test tool for deletion
            from models.tool import ToolRegistryEntry, ToolCategory, ToolStatus
            test_tool = ToolRegistryEntry(
                name="uat_deletion_test",
                description="Tool for deletion testing",
                server_id="uat-server",
                category=ToolCategory.GENERAL,
                status=ToolStatus.AVAILABLE
            )
            
            tool_manager.register_tool(test_tool)
            print("   ‚úì Step 2: Created test tool for deletion")
            
            # Step 3: Verify tool was created
            all_tools = tool_manager.get_all_tools()
            test_tool_found = any(tool.name == "uat_deletion_test" for tool in all_tools)
            assert test_tool_found, "Test tool should be found"
            print("   ‚úì Step 3: Test tool found in registry")
            
            # Step 4: Delete the test tool
            deletion_success = tool_manager.delete_tool(test_tool.id)
            assert deletion_success, "Tool deletion should succeed"
            print("   ‚úì Step 4: Test tool deleted successfully")
            
            # Step 5: Verify tool was deleted
            updated_tools = tool_manager.get_all_tools()
            test_tool_still_exists = any(tool.name == "uat_deletion_test" for tool in updated_tools)
            assert not test_tool_still_exists, "Test tool should be deleted"
            print("   ‚úì Step 5: Verified tool was removed from registry")
            
            self.test_results['tool_management'] = True
            print("   ‚úÖ Tool Management Operations: PASSED")
            
        except Exception as e:
            self.test_results['tool_management'] = False
            print(f"   ‚ùå Tool Management Operations: FAILED - {e}")
    
    def cleanup_uat_environment(self):
        """Clean up UAT environment"""
        print("\nCleaning up UAT environment...")
        
        try:
            if os.path.exists(self.test_dir):
                shutil.rmtree(self.test_dir)
            print("‚úì UAT environment cleanup complete")
            
        except Exception as e:
            print(f"‚úó UAT environment cleanup failed: {e}")
    
    def generate_uat_report(self):
        """Generate UAT report"""
        print("\n" + "="*80)
        print("USER ACCEPTANCE TESTING (UAT) REPORT")
        print("="*80)
        
        total_scenarios = len(self.test_results)
        passed_scenarios = sum(1 for result in self.test_results.values() if result)
        failed_scenarios = total_scenarios - passed_scenarios
        
        print(f"\nUAT Summary:")
        print(f"  Total Scenarios: {total_scenarios}")
        print(f"  Passed: {passed_scenarios}")
        print(f"  Failed: {failed_scenarios}")
        print(f"  Success Rate: {(passed_scenarios/total_scenarios)*100:.1f}%")
        
        print(f"\nDetailed Results:")
        scenario_names = {
            'server_operations': 'Basic Server Operations',
            'tool_discovery': 'Tool Discovery Workflow',
            'tool_execution': 'Basic Tool Execution',
            'security_audit': 'Security and Audit Logging',
            'tool_management': 'Tool Management Operations'
        }
        
        for scenario_key, result in self.test_results.items():
            scenario_name = scenario_names.get(scenario_key, scenario_key)
            status = "‚úÖ PASS" if result else "‚ùå FAIL"
            print(f"  {scenario_name}: {status}")
        
        print(f"\nUser Experience Assessment:")
        if failed_scenarios == 0:
            print("  üéâ EXCELLENT - All core user workflows are working perfectly!")
            print("  The application is ready for production deployment.")
            ux_rating = "EXCELLENT"
        elif failed_scenarios <= 1:
            print("  ‚úÖ GOOD - Core functionality is solid with minor issues.")
            print("  Address the failed scenario and proceed to production.")
            ux_rating = "GOOD"
        else:
            print("  ‚ö†Ô∏è  NEEDS ATTENTION - Multiple core workflows have issues.")
            print("  Address failed scenarios before production deployment.")
            ux_rating = "NEEDS_ATTENTION"
        
        print(f"\nTask 20.2 Status:")
        if ux_rating in ["EXCELLENT", "GOOD"]:
            print("  ‚úÖ Task 20.2 (User Acceptance Testing) COMPLETED")
            print("  Core user workflows validated successfully")
            print("  System ready for Task 20.3 (Documentation and Deployment)")
        else:
            print("  üîÑ Task 20.2 needs additional work")
            print("  Fix failed scenarios and re-run UAT")
        
        print(f"\nNext Steps:")
        if ux_rating == "EXCELLENT":
            print("  1. ‚úÖ Proceed to Task 20.3 (Documentation and Deployment)")
            print("  2. Create user documentation and deployment guides")
            print("  3. Prepare production deployment")
        elif ux_rating == "GOOD":
            print("  1. Fix the minor issue in the failed scenario")
            print("  2. Proceed to Task 20.3 (Documentation and Deployment)")
            print("  3. Monitor the fixed area in production")
        else:
            print("  1. Analyze and fix all failed scenarios")
            print("  2. Re-run UAT to validate fixes")
            print("  3. Only proceed to Task 20.3 after UAT passes")
        
        print("="*80)
        
        return ux_rating in ["EXCELLENT", "GOOD"]


def main():
    """Run Simplified User Acceptance Testing"""
    print("MCP Admin Application - Simplified User Acceptance Testing")
    print("=" * 80)
    
    uat_suite = SimplifiedUAT()
    
    try:
        # Setup UAT environment
        if not uat_suite.setup_uat_environment():
            return 1
        
        # Run core user scenarios
        uat_suite.test_scenario_1_basic_server_operations()
        uat_suite.test_scenario_2_tool_discovery_workflow()
        uat_suite.test_scenario_3_tool_execution_basics()
        uat_suite.test_scenario_4_security_audit_logging()
        uat_suite.test_scenario_5_tool_management_operations()
        
        # Generate UAT report
        success = uat_suite.generate_uat_report()
        
        return 0 if success else 1
        
    except Exception as e:
        print(f"\n‚ùå Critical UAT failure: {e}")
        return 1
        
    finally:
        uat_suite.cleanup_uat_environment()


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)